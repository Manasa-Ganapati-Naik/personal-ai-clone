# Bibliography (Key Reads)

1. Vaswani et al., Attention is All You Need. [PDF](research/attention_is_all_you_need.pdf)
   - Notes: Transformer backbone; essential for model selection and understanding self-attention.

2. Houlsby et al., Parameter-Efficient Transfer Learning (Adapters). [PDF](research/houlsby_adapters.pdf)
   - Notes: Adapter tuning reduces data requirements; candidate approach for fine-tuning.

3. Paper on personalization and few-shot adaptation. [PDF](research/personalization_fewshot.pdf)
   - Notes: Strategies for personalizing conversational agents.

4. GDPR overview — EU GDPR summary. [PDF](research/gdpr_overview.pdf)
   - Notes: Privacy regulations; consent requirements for NLP applications.

5. Hugging Face Transformers — Fine-tuning guide. [PDF](research/huggingface_finetuning.pdf)
   - Notes: Official tutorial for fine-tuning transformer-based language models.


